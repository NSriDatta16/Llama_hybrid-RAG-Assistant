# Llama-Hybrid-RAG-Assistant  
### *An AI Retrieval-Augmented Generation Assistant built with Llama 3, FAISS, BM25, and persistent memory.*

---
## ğŸš€ Overview
The **Llama Hybrid RAG Assistant** is a **Retrieval-Augmented Generation (RAG)** system powered by **Groqâ€™s Llama 3**, **FAISS dense embeddings**, and **BM25 sparse retrieval**.  
It enables intelligent, context-aware conversations over large text datasets (Wikipedia, StackExchange, arXiv, etc.) using **hybrid retrieval** and **persistent chat memory**.

This project demonstrates a complete **local RAG pipeline** with:
- FastAPI backend  
- Streamlit chat frontend  
- Hybrid search (FAISS + BM25)  
- Llama-3 (Groq API) inference  
- Conversational memory persistence  

---

## ğŸ§© Architecture

```plaintext
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚           User (UI)           â”‚
                â”‚   Streamlit Chat Interface     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      FastAPI Backend    â”‚
                    â”‚   (backend/main.py)     â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚  Retrieval Layer        â”‚
                    â”‚   â€¢ FAISS (dense)       â”‚
                    â”‚   â€¢ BM25 (sparse)       â”‚
                    â”‚   â€¢ Hybrid Combiner     â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚  LLM Inference Layer    â”‚
                    â”‚   â€¢ Groq (Llama 3 API)  â”‚
                    â”‚   â€¢ OpenAI (fallback)   â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚  Memory + Session Store â”‚
                    â”‚   â€¢ JSON persistence    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚      Local Data Sources     â”‚
                  â”‚  Wikipedia / StackExchange  â”‚
                  â”‚  arXiv / Custom Text Files  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
